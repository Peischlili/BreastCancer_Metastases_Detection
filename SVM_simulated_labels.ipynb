{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "import sklearn.model_selection\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore ResNet feature matrices\n",
    "image_folder = \"train_input/resnet_features/\"\n",
    "\n",
    "# function to load folder into arrays and then it returns that same array\n",
    "def loadImages(path):\n",
    "    image_files = sorted([os.path.join(path, file)\n",
    "         for file in os.listdir(path) if file.endswith('.npy')])\n",
    "    return image_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_features(filenames):\n",
    "    \"\"\"Load and aggregate the resnet features by the average.\n",
    "\n",
    "    Args:\n",
    "        filenames: list of filenames of length `num_patients` corresponding to resnet features\n",
    "\n",
    "    Returns:\n",
    "        features: np.array of mean resnet features, shape `(num_patients, 2048)`\n",
    "    \"\"\"\n",
    "    # Load numpy arrays\n",
    "    features = []\n",
    "    for f in filenames:\n",
    "        patient_features = np.load(f)\n",
    "\n",
    "        # Remove location features (but we could use them?)\n",
    "        patient_features = patient_features[:, 3:]\n",
    "\n",
    "        aggregated_features = np.mean(patient_features, axis=0)\n",
    "        features.append(aggregated_features)\n",
    "\n",
    "    features = np.stack(features, axis=0)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load feature npy folder into arrays and returns that same array of strings\n",
    "def loadFiles(path):\n",
    "    feature_files = sorted([os.path.join(path, file)\n",
    "         for file in os.listdir(path) if file.endswith('.npy')])\n",
    "    return feature_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precise training set and test set relative location\n",
    "\n",
    "train_dir = Path(\"train_input/resnet_features\")\n",
    "test_dir = Path(\"test_input/resnet_features\")\n",
    "\n",
    "train_output_filename = Path(\"training_output.csv\")\n",
    "\n",
    "train_output = pd.read_csv(train_output_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Use locally annotated information</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old id looks like: ID_387_annotated_tile_0_15_69_30.jpg\n",
    "# reformat the annotation id for upcoming df joining\n",
    "# function for label file\n",
    "\n",
    "def get_new_id(old_id):\n",
    "    # get rid of the .jpg extension\n",
    "    old_id = Path(old_id).stem\n",
    "    # store all characters in a list\n",
    "    string_list = old_id.split('_')\n",
    "    # new_id looks like: <patient_id>_<zoom_level>_<x_coord>_<y_coord>\n",
    "    new_id = f\"{string_list[0]}_{string_list[1]}_{string_list[-3]}_{string_list[-2]}_{string_list[-1]}\"\n",
    "    return new_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load local annotations (tile-level)\n",
    "# id goes as follows: <patient_id>_annotated_tile_<tile_id>_<tile_coords>\n",
    "local_annot = pd.read_csv('train_input/train_tile_annotations.csv')\n",
    "local_annot.rename(columns={'Unnamed: 0': 'Tile_annotation_id'}, inplace=True)\n",
    "\n",
    "# add new column new_id\n",
    "local_annot['new_tile_id'] = local_annot['Tile_annotation_id'].map(get_new_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load 11 annotated npy files in resnet features folder\n",
    "def loadAnnotatedData(path):\n",
    "    feature_files = sorted([os.path.join(path, file)\n",
    "         for file in os.listdir(path) if file.endswith('_annotated.npy')])\n",
    "    return feature_files\n",
    "\n",
    "\n",
    "# compile all locally annotated data into a dataframe to form strong supervised dataset\n",
    "def dataCompiler(filelist):\n",
    "    df_data = pd.DataFrame()\n",
    "    \n",
    "    # Load numpy arrays\n",
    "    for f in filelist:\n",
    "        try:\n",
    "            patient_features = np.load(f)\n",
    "            patient_id = Path(f).stem.strip(\"_annotated\")\n",
    "\n",
    "            # add patient id to features\n",
    "            df_patient = pd.DataFrame(data=patient_features)\n",
    "            df_patient['patient_id'] = patient_id\n",
    "\n",
    "            # add df to global dataframe\n",
    "            df_data = df_data.append(df_patient, ignore_index=True)\n",
    "        \n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "    \n",
    "    # rename dataframe with proper column names\n",
    "    colnames = ['zoom_level', 'x_coord', 'y_coord'] + [i for i in range(1,2049)] + ['patient_id']\n",
    "    df_data.columns = colnames\n",
    "    \n",
    "    return df_data\n",
    "\n",
    "\n",
    "# generate new_id for annotated data\n",
    "def generate_new_id(patient_id, zoom, x, y):\n",
    "    element_list = [patient_id, str(int(zoom)), str(int(x)), str(int(y))]\n",
    "    separator = \"_\"\n",
    "    new_id = separator.join(element_list)\n",
    "    return new_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gives the list of annotated patient npy files\n",
    "annotatedFiles_train = loadAnnotatedData(train_dir)\n",
    "\n",
    "# complete annotated dataset\n",
    "annotatedData = dataCompiler(annotatedFiles_train)\n",
    "\n",
    "# add new column new_tile_id\n",
    "annotatedData['new_tile_id']:str = annotatedData.apply(lambda x: generate_new_id(x.patient_id, x.zoom_level, x.x_coord, x.y_coord),  axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the features table and label table with newly created new_tile_id\n",
    "data = annotatedData.merge(local_annot, how='inner', on='new_tile_id')\n",
    "\n",
    "# Separate now local features and target for models\n",
    "# local features for train (tile-level)\n",
    "local_features = np.array(data.iloc[:, 3:2051])\n",
    "\n",
    "# local targets (tile-level)\n",
    "local_labels = data[\"Target\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Apply SVM to local annotated data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get filenames for train\n",
    "filenames_train = loadFiles(train_dir)\n",
    "\n",
    "# Get global labels (patient-wise) for train\n",
    "labels_train = train_output[\"Target\"].values\n",
    "\n",
    "# check if the number of observations and labels corresponds\n",
    "assert len(filenames_train) == len(labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the numpy filenames for test\n",
    "filenames_test = loadFiles(test_dir)\n",
    "# ID list without its suffix (ex: \"ID_005\")\n",
    "ids_test = [Path(f).stem for f in filenames_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the resnet features and aggregate them by the average\n",
    "features_train = get_average_features(filenames_train)\n",
    "features_test = get_average_features(filenames_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given path of a filename, returns a numpy array\n",
    "def get_tile_features(filename):\n",
    "    # Load npy to numpy arrays \n",
    "    patient_features = np.load(filename)\n",
    "    \n",
    "    # Remove location features (but we could use them?)\n",
    "    patient_features = patient_features[:, 3:]\n",
    "    return patient_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting strong labels by tile-level resnet\n",
      "AUC: mean 0.919714839559539, std 0.01773988538222485\n",
      "Accuracy: mean 0.9578557068267216, std 0.004225995867068012\n",
      "True Positive Rate: mean 0.714234342223554, std 0.044187437945193704\n"
     ]
    }
   ],
   "source": [
    "# Evaluate SVM model without C parameter\n",
    "\n",
    "# number of runs for cross-validation\n",
    "num_runs = 3\n",
    "# number of splits for cross-validation\n",
    "num_splits = 5\n",
    "\n",
    "# Multiple cross validations on the local feature training set\n",
    "aucs = []\n",
    "accuracies =[]\n",
    "recalls = []\n",
    "\n",
    "# Standardize training features\n",
    "scaler = StandardScaler()\n",
    "train_X = scaler.fit_transform(local_features)\n",
    "\n",
    "for seed in range(num_runs):\n",
    "    #Create a SVM Classifier without C parameter\n",
    "    clf = svm.SVC(kernel='linear')\n",
    "\n",
    "    cv = sklearn.model_selection.StratifiedKFold(n_splits=num_splits, shuffle=True, random_state=seed)\n",
    "\n",
    "    # Cross validation on the training set\n",
    "    auc = sklearn.model_selection.cross_val_score(clf, X=train_X, y=local_labels,\n",
    "                                                  cv=cv, scoring=\"roc_auc\", verbose=0)\n",
    "    accuracy = sklearn.model_selection.cross_val_score(clf, X=train_X, y=local_labels,\n",
    "                                                  cv=cv, scoring=\"accuracy\", verbose=0)\n",
    "    recall = sklearn.model_selection.cross_val_score(clf, X=train_X, y=local_labels,\n",
    "                                                  cv=cv, scoring=\"recall\", verbose=0)\n",
    "    \n",
    "    aucs.append(auc)\n",
    "    accuracies.append(accuracy)\n",
    "    recalls.append(recall)\n",
    "\n",
    "aucs = np.array(aucs)\n",
    "accuracies = np.array(accuracies)\n",
    "recalls = np.array(recalls)\n",
    "\n",
    "print(\"Predicting strong labels by tile-level resnet\")\n",
    "print(\"AUC: mean {}, std {}\".format(aucs.mean(), aucs.std()))\n",
    "print(\"Accuracy: mean {}, std {}\".format(accuracies.mean(), accuracies.std()))\n",
    "print(\"True Positive Rate: mean {}, std {}\".format(recalls.mean(), recalls.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When c_coeff is 0.008\n",
      "AUC: mean 0.9409161675829241, std 0.009161927498755718\n",
      "Accuracy: mean 0.9711573220123946, std 0.005224424078312489\n",
      "True Positive Rate: mean 0.7156128258915194, std 0.04897567906589284\n",
      "When c_coeff is 0.04\n",
      "AUC: mean 0.9227796457698807, std 0.018378565926560293\n",
      "Accuracy: mean 0.9599958522422289, std 0.006192905181682128\n",
      "True Positive Rate: mean 0.7198281889921087, std 0.06031469059858214\n",
      "When c_coeff is 0.2\n",
      "AUC: mean 0.9185350830270054, std 0.02124387175568656\n",
      "Accuracy: mean 0.9584154101400477, std 0.0062590471388418055\n",
      "True Positive Rate: mean 0.7184197382878833, std 0.0665063473717086\n",
      "When c_coeff is 1.0\n",
      "AUC: mean 0.9185350830270054, std 0.02124387175568656\n",
      "Accuracy: mean 0.9584154101400477, std 0.0062590471388418055\n",
      "True Positive Rate: mean 0.7184197382878833, std 0.0665063473717086\n",
      "When c_coeff is 5.0\n",
      "AUC: mean 0.9185350830270054, std 0.02124387175568656\n",
      "Accuracy: mean 0.9584154101400477, std 0.0062590471388418055\n",
      "True Positive Rate: mean 0.7184197382878833, std 0.0665063473717086\n",
      "When c_coeff is 25.0\n",
      "AUC: mean 0.9185350830270054, std 0.02124387175568656\n",
      "Accuracy: mean 0.9584154101400477, std 0.0062590471388418055\n",
      "True Positive Rate: mean 0.7184197382878833, std 0.0665063473717086\n",
      "When c_coeff is 125.0\n",
      "AUC: mean 0.9185350830270054, std 0.02124387175568656\n",
      "Accuracy: mean 0.9584154101400477, std 0.0062590471388418055\n",
      "True Positive Rate: mean 0.7184197382878833, std 0.0665063473717086\n"
     ]
    }
   ],
   "source": [
    "# Evaluate SVM models with hyperparameter C\n",
    "\n",
    "# Test using the following values for coefficient 'c'\n",
    "c_coeff = np.array([5**-3, 5**-2, 5**-1, 1 , 5 , 5**2, 5**3])\n",
    "\n",
    "# number of runs for cross-validation\n",
    "num_runs = 3\n",
    "# number of splits for cross-validation\n",
    "num_splits = 5\n",
    "\n",
    "# Multiple cross validations on the local feature training set\n",
    "aucs = []\n",
    "accuracies =[]\n",
    "recalls = []\n",
    "\n",
    "# Standardize training features\n",
    "scaler = StandardScaler()\n",
    "train_X = scaler.fit_transform(local_features)\n",
    "\n",
    "for i in c_coeff:\n",
    "    # create a SVM classifier with various C parameter values\n",
    "    svf = SVC(C=i, kernel='linear')\n",
    "\n",
    "    cv = sklearn.model_selection.StratifiedKFold(n_splits=num_splits, shuffle=True, random_state=seed)\n",
    "\n",
    "    # Cross validation on the training set\n",
    "    auc = sklearn.model_selection.cross_val_score(svf, X=train_X, y=local_labels,\n",
    "                                              cv=cv, scoring=\"roc_auc\", verbose=0)\n",
    "    accuracy = sklearn.model_selection.cross_val_score(svf, X=train_X, y=local_labels,\n",
    "                                              cv=cv, scoring=\"accuracy\", verbose=0)\n",
    "    recall = sklearn.model_selection.cross_val_score(svf, X=train_X, y=local_labels,\n",
    "                                              cv=cv, scoring=\"recall\", verbose=0)\n",
    "\n",
    "    print(f\"When c_coeff is {i}\")\n",
    "    print(\"AUC: mean {}, std {}\".format(auc.mean(), auc.std()))\n",
    "    print(\"Accuracy: mean {}, std {}\".format(accuracy.mean(), accuracy.std()))\n",
    "    print(\"True Positive Rate: mean {}, std {}\".format(recall.mean(), recall.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Grid Search for SVM with RBF Kernel</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is usually a good idea to scale the data for SVM training.\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(local_features)\n",
    "\n",
    "# Train classifiers\n",
    "# For an initial search, a logarithmic grid with basis\n",
    "# 10 is often helpful. Using a basis of 2, a finer\n",
    "# tuning can be achieved but at a much higher cost.\n",
    "\n",
    "C_range = np.logspace(-2, 10, 13)\n",
    "gamma_range = np.logspace(-9, 3, 13)\n",
    "param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "cv = sklearn.model_selection.StratifiedKFold(n_splits=num_splits, shuffle=True, random_state=42)\n",
    "grid = sklearn.model_selection.GridSearchCV(SVC(), param_grid=param_grid, cv=cv)\n",
    "grid.fit(X, local_labels)\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (grid.best_params_, grid.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Finally the grid search of RBF takes too long to find the optimal hyperparameters. Since the data dimension is relatively high, theoractically there is no need for data projection and the linear kernel can reach comparable performance. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Create added training set with unlabeled positive cases</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-24-77232071a7d5>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  positive_patients['npy_ID'] = positive_patients.apply(lambda x: f\"ID_{str(x['ID']).zfill(3)}.npy\", axis=1)\n"
     ]
    }
   ],
   "source": [
    "# retrieve all positive patient case\n",
    "positive_patients = train_output[train_output['Target']==1]\n",
    "positive_patients['npy_ID'] = positive_patients.apply(lambda x: f\"ID_{str(x['ID']).zfill(3)}.npy\", axis=1)\n",
    "\n",
    "# store all positive case npys to an array for compilation\n",
    "added_pat_list = np.array(positive_patients['npy_ID'])\n",
    "added_pat_list = [f\"train_input/resnet_features/{i}\" for i in added_pat_list]\n",
    "\n",
    "# Compile unlabeled positive cases in training set\n",
    "posData = dataCompiler(added_pat_list)\n",
    "\n",
    "# add new column new_tile_id\n",
    "posData['new_tile_id']:str = posData.apply(lambda x: generate_new_id(x.patient_id, x.zoom_level, x.x_coord, x.y_coord),  axis = 1)\n",
    "    \n",
    "# create a training test set for prediction\n",
    "added_features = np.array(posData.iloc[:, 3:2051])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Train SVM model with tuned hyperparameter and predict on the added unlabeled set</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize training and test features\n",
    "scaler = StandardScaler()\n",
    "train_X = scaler.fit_transform(local_features)\n",
    "test_X = scaler.transform(added_features)\n",
    "\n",
    "# Use the tile-level resnet features to predict the labels\n",
    "# Create a svm Classifier\n",
    "clf = svm.SVC(C=0.008, kernel='linear', probability=True)\n",
    "\n",
    "# Train the model using the training sets\n",
    "clf.fit(train_X, local_labels)\n",
    "\n",
    "# Predict the response for test dataset\n",
    "y_pred = clf.predict(test_X)\n",
    "y_pred_proba = clf.predict_proba(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recap prediction info to dataframe\n",
    "recap = pd.DataFrame(data=y_pred_proba)\n",
    "recap['Target'] = y_pred\n",
    "recap['patient_id'] = posData['patient_id']\n",
    "recap.columns = ['negative', 'positive', 'Target', 'ID']\n",
    "\n",
    "# aggregation: count number of positive and negative cases for each patient\n",
    "recap_count = pd.pivot_table(recap, index=['ID'], columns=['Target'], aggfunc={'Target': 'count'})\n",
    "recap_count.columns = ['NB_neg', 'NB_pos']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Top Scoring example selection on predicted data and form new training set</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is 2 wrong categorical prediction(s).\n"
     ]
    }
   ],
   "source": [
    "# check if patient-level data to be eliminated\n",
    "eliminated = recap_count[recap_count['NB_pos'].isnull()]\n",
    "\n",
    "# all global categorical predictions should point to positive => NB_pos shouldn't be NaN\n",
    "print(f\"There is {len(eliminated)} wrong categorical prediction(s).\")\n",
    "\n",
    "# create list of patient_ID to eliminated\n",
    "eliminated.reset_index(inplace=True)\n",
    "eli_list = list(eliminated['ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top Scoring example selection \n",
    "# to form a simulated dataset to complete the old locally annotated one \n",
    "posData['Target'] = y_pred\n",
    "posData['positive_proba'] = recap['positive']\n",
    "neg_examples = posData[posData['positive_proba']<0.003]\n",
    "pos_examples = posData[posData['positive_proba']>=0.95]\n",
    "selected_examples = pd.concat([neg_examples, pos_examples], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminate those samples in the list from the data set\n",
    "selected_examples = selected_examples[~selected_examples['patient_id'].isin(eli_list)]\n",
    "\n",
    "# form simulated dataset from unlabeled data\n",
    "simulated_features = np.array(selected_examples.iloc[:, 3:2051])\n",
    "simulated_labels = selected_examples['Target'].values\n",
    "\n",
    "# add the simulated features and labels to labelised training data\n",
    "# to form a bigger training set\n",
    "new_features = np.append(local_features, simulated_features, axis=0)\n",
    "new_labels = np.append(local_labels, simulated_labels, axis=0)\n",
    "assert new_features.shape[0] == new_labels.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Take newly-formed dataset as input and predict on the test set</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the new model trained with new dataset\n",
    "\n",
    "# number of runs for cross-validation\n",
    "num_runs = 3\n",
    "# number of splits for cross-validation\n",
    "num_splits = 5\n",
    "\n",
    "# Multiple cross validations on the local feature training set\n",
    "aucs = []\n",
    "accuracies =[]\n",
    "recalls = []\n",
    "\n",
    "# Standardize training and test features and apply standardization to test features\n",
    "scaler = StandardScaler()\n",
    "train_X = scaler.fit_transform(new_features)\n",
    "\n",
    "for seed in range(num_runs):\n",
    "    #Create a svm Classifier\n",
    "    clf = svm.SVC(C=0.008, kernel='linear', probability=True) # Linear Kernel without C parameter\n",
    "\n",
    "    cv = sklearn.model_selection.StratifiedKFold(n_splits=num_splits, shuffle=True, random_state=seed)\n",
    "\n",
    "    # Cross validation on the training set\n",
    "    auc = sklearn.model_selection.cross_val_score(clf, X=train_X, y=new_labels,\n",
    "                                                  cv=cv, scoring=\"roc_auc\", verbose=0)\n",
    "    accuracy = sklearn.model_selection.cross_val_score(clf, X=train_X, y=new_labels,\n",
    "                                                  cv=cv, scoring=\"accuracy\", verbose=0)\n",
    "    recall = sklearn.model_selection.cross_val_score(clf, X=train_X, y=new_labels,\n",
    "                                                  cv=cv, scoring=\"recall\", verbose=0)\n",
    "    \n",
    "    aucs.append(auc)\n",
    "    accuracies.append(accuracy)\n",
    "    recalls.append(recall)\n",
    "\n",
    "aucs = np.array(aucs)\n",
    "accuracies = np.array(accuracies)\n",
    "recalls = np.array(recalls)\n",
    "\n",
    "print(\"Predicting strong labels by tile-level resnet\")\n",
    "print(\"AUC: mean {}, std {}\".format(aucs.mean(), aucs.std()))\n",
    "print(\"Accuracy: mean {}, std {}\".format(accuracies.mean(), accuracies.std()))\n",
    "print(\"True Positive Rate: mean {}, std {}\".format(recalls.mean(), recalls.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test set\n",
    "\n",
    "# empty df to store output of all patients\n",
    "df_output = pd.DataFrame()\n",
    "\n",
    "# Standardize training and test features and apply standardization to test features\n",
    "scaler = StandardScaler()\n",
    "train_X = scaler.fit_transform(new_features)\n",
    "\n",
    "# Use the tile-level resnet features to predict the labels\n",
    "# Create a svm Classifier\n",
    "clf = svm.SVC(C=0.008, kernel='linear', probability=True)\n",
    "\n",
    "# Train the model using the training sets\n",
    "clf.fit(train_X, new_labels)\n",
    "\n",
    "for f in filenames_test: \n",
    "    patient_id:str = Path(f).stem.split(\"ID_\")[1]\n",
    "    test_X = get_tile_features(f)\n",
    "    \n",
    "    # do the PCA transformation on test set\n",
    "    test_X = scaler.transform(test_X)\n",
    "    \n",
    "    # Predict the response for test dataset\n",
    "    y_pred = clf.predict(test_X)\n",
    "    y_pred_proba = clf.predict_proba(test_X)[:, 1] #keep only positive probability\n",
    "    \n",
    "    # Check that predictions are in [0, 1]\n",
    "    assert np.max(y_pred_proba) <= 1.0\n",
    "    assert np.min(y_pred_proba) >= 0.0\n",
    "    \n",
    "    test_output = pd.DataFrame({\"ID\": patient_id, \"Target\": y_pred_proba, \"Category\": y_pred})\n",
    "    df_output = df_output.append(test_output, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if positive proba is absent, ie. no positive class detected for a patient\n",
    "# choose negative proba. Otherwise, use positive proba\n",
    "def select_final_proba(pos_proba, nega_proba):\n",
    "    if np.isnan(pos_proba):\n",
    "        final_proba = nega_proba\n",
    "    else:\n",
    "        final_proba = pos_proba\n",
    "    return final_proba\n",
    "\n",
    "# create recap table with aggregated information\n",
    "recap = pd.pivot_table(df_output, values='Target', index=['ID'], columns=['Category'], aggfunc={'Target': np.mean})\n",
    "# rename recap table columns\n",
    "colnames = ['negative_proba', 'positive_proba']\n",
    "recap.columns = colnames\n",
    "\n",
    "# apply final proba selection at patient-level and create new column\n",
    "recap['Target'] = recap.apply(lambda x: select_final_proba(x.positive_proba, x.negative_proba), axis=1)\n",
    "\n",
    "# drop useless columns and save result to csv\n",
    "output = recap.drop(columns=['negative_proba', 'positive_proba'])\n",
    "output.to_csv(\"predictions/SVM_with_simulated_labels.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
